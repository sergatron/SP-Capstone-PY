{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pv_df_orig = pd.read_csv('Capstone/openpv_all.csv', sep=',', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1020583 entries, 0 to 1020582\n",
      "Data columns (total 81 columns):\n",
      "state                          1020583 non-null object\n",
      "date_installed                 1020578 non-null object\n",
      "incentive_prog_names           797958 non-null object\n",
      "type                           1020578 non-null object\n",
      "size_kw                        1020578 non-null float64\n",
      "appraised                      224036 non-null object\n",
      "zipcode                        1020578 non-null float64\n",
      "install_type                   978002 non-null object\n",
      "installer                      702521 non-null object\n",
      "cost_per_watt                  763002 non-null float64\n",
      "cost                           999030 non-null object\n",
      "lbnl_tts_version_year          797958 non-null float64\n",
      "lbnl_tts                       797958 non-null object\n",
      "city                           799016 non-null object\n",
      "utility_clean                  792720 non-null object\n",
      "tech_1                         580919 non-null object\n",
      "model1_clean                   580919 non-null object\n",
      "county                         998652 non-null object\n",
      "annual_PV_prod                 780969 non-null float64\n",
      "annual_insolation              780969 non-null float64\n",
      "rebate                         386729 non-null object\n",
      "sales_tax_cost                 355309 non-null float64\n",
      "tilt1                          383365 non-null float64\n",
      "tracking_type                  526058 non-null object\n",
      "azimuth1                       363281 non-null float64\n",
      "manuf2_clean                   231607 non-null object\n",
      "manuf3_clean                   209653 non-null object\n",
      "manuf1_clean                   201121 non-null object\n",
      "inv_man_clean                  49933 non-null object\n",
      "reported_annual_energy_prod    204429 non-null float64\n",
      "incentivetype                  0 non-null float64\n",
      "year_app_implied               0 non-null float64\n",
      "year                           68 non-null object\n",
      "npv_fit_real                   0 non-null float64\n",
      "application_implied            0 non-null float64\n",
      "npv_pbi_real                   0 non-null float64\n",
      "other_incentive                0 non-null float64\n",
      "appraised_cluster              0 non-null float64\n",
      "inflation                      0 non-null float64\n",
      "other_incentive_real           0 non-null float64\n",
      "zip_available                  0 non-null float64\n",
      "cust_city                      0 non-null float64\n",
      "pbi                            0 non-null float64\n",
      "pbi_real                       0 non-null float64\n",
      "pbi_length                     5427 non-null float64\n",
      "application                    0 non-null float64\n",
      "fit_length                     0 non-null float64\n",
      "fit_rate                       0 non-null float64\n",
      "fit_payment                    0 non-null float64\n",
      "_3rdparty_implied              0 non-null float64\n",
      "utility                        2117 non-null object\n",
      "install_price_real_w           0 non-null float64\n",
      "install_price                  0 non-null float64\n",
      "installer_clean                0 non-null float64\n",
      "manuf1_                        0 non-null float64\n",
      "inverter_reported              0 non-null float64\n",
      "rebate_real                    0 non-null float64\n",
      "model1                         0 non-null float64\n",
      "_3rdparty                      0 non-null float64\n",
      "inv_model_reported             0 non-null float64\n",
      "microinv_solarhub              0 non-null float64\n",
      "bipv_3                         5255 non-null float64\n",
      "bipv_2                         5255 non-null float64\n",
      "bipv_1                         5255 non-null float64\n",
      "sales_tax_rate                 0 non-null float64\n",
      "sales_tax_cost_real            0 non-null float64\n",
      "bipv_all                       0 non-null float64\n",
      "thinfilm_all                   0 non-null float64\n",
      "china                          0 non-null float64\n",
      "sys_sizeac                     0 non-null float64\n",
      "pbi_rate                       0 non-null float64\n",
      "new_constr                     27106 non-null float64\n",
      "effic_1                        0 non-null float64\n",
      "cust_county                    0 non-null float64\n",
      "tracking                       1930 non-null float64\n",
      "inv_model_clean                0 non-null float64\n",
      "mod_cost_real                  0 non-null float64\n",
      "inv_cost_real                  0 non-null float64\n",
      "bos_powerclerk_real            0 non-null float64\n",
      "permitting_real                0 non-null float64\n",
      "3rdparty                       306993 non-null float64\n",
      "dtypes: float64(59), object(22)\n",
      "memory usage: 630.7+ MB\n"
     ]
    }
   ],
   "source": [
    "pv_df_orig.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column removed: manuf1_clean\n",
      "column removed: inv_man_clean\n",
      "column removed: incentivetype\n",
      "column removed: year_app_implied\n",
      "column removed: year\n",
      "column removed: npv_fit_real\n",
      "column removed: application_implied\n",
      "column removed: npv_pbi_real\n",
      "column removed: other_incentive\n",
      "column removed: appraised_cluster\n",
      "column removed: inflation\n",
      "column removed: other_incentive_real\n",
      "column removed: zip_available\n",
      "column removed: cust_city\n",
      "column removed: pbi\n",
      "column removed: pbi_real\n",
      "column removed: pbi_length\n",
      "column removed: application\n",
      "column removed: fit_length\n",
      "column removed: fit_rate\n",
      "column removed: fit_payment\n",
      "column removed: _3rdparty_implied\n",
      "column removed: utility\n",
      "column removed: install_price_real_w\n",
      "column removed: install_price\n",
      "column removed: installer_clean\n",
      "column removed: manuf1_\n",
      "column removed: inverter_reported\n",
      "column removed: rebate_real\n",
      "column removed: model1\n",
      "column removed: _3rdparty\n",
      "column removed: inv_model_reported\n",
      "column removed: microinv_solarhub\n",
      "column removed: bipv_3\n",
      "column removed: bipv_2\n",
      "column removed: bipv_1\n",
      "column removed: sales_tax_rate\n",
      "column removed: sales_tax_cost_real\n",
      "column removed: bipv_all\n",
      "column removed: thinfilm_all\n",
      "column removed: china\n",
      "column removed: sys_sizeac\n",
      "column removed: pbi_rate\n",
      "column removed: new_constr\n",
      "column removed: effic_1\n",
      "column removed: cust_county\n",
      "column removed: tracking\n",
      "column removed: inv_model_clean\n",
      "column removed: mod_cost_real\n",
      "column removed: inv_cost_real\n",
      "column removed: bos_powerclerk_real\n",
      "column removed: permitting_real\n"
     ]
    }
   ],
   "source": [
    "# FUNCTION: remove NULL columns\n",
    "def remove_null_col(df, percent=80):\n",
    "  '''Remove all columns with too many null values'''\n",
    "  keeper_list = []\n",
    "  # loser_list = []\n",
    "  col_list = list(df.columns)\n",
    "  # iterate through each column\n",
    "  for col_name in col_list:\n",
    "    # A and B are the conditions for removing columns\n",
    "    nan_count = pd.isnull(df[col_name]).sum()\n",
    "    A = df[col_name].isnull().all()\n",
    "    B = nan_count/len(df.index)*100 > percent\n",
    "    # if column is empty or more than 20% of columns is NaN, then discard, else keep\n",
    "    if (A | B):\n",
    "      # place column into a keeper list\n",
    "      # loser_list.append(col_name)\n",
    "      print('column removed:', col_name)\n",
    "    else:\n",
    "      keeper_list.append(col_name)\n",
    "  #pv_df = df[keeper_list]\n",
    "  return df[keeper_list]\n",
    "pv_df = remove_null_col(pv_df_orig, 80.0)\n",
    "\n",
    "# NOTE: use dropna(axis=1, how='all') to drop entire column\n",
    "pv_df = pv_df[['date_installed', 'city','state','zipcode', 'county', 'size_kw','annual_insolation',\n",
    "               'annual_PV_prod', 'reported_annual_energy_prod',\n",
    "               'cost_per_watt','cost', 'sales_tax_cost', 'rebate', 'incentive_prog_names', 'install_type',\n",
    "               'installer','utility_clean']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: state \n",
      "Missing values: 0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# CONVERT DATA TYPE OF 'ZIPCODES'\n",
    "# convert to numpy array, replace missing values with 0, then convert data type\n",
    "pv_df['zipcode'] = np.nan_to_num(pv_df['zipcode'].values).astype(int)\n",
    "\n",
    "\n",
    "def missing_val_count(df, col_name, show_missing=False):\n",
    "  '''Count missing values and show its index.'''\n",
    "  print('\\nColumn:', col_name, '\\nMissing values:', np.count_nonzero(df.loc[:, col_name].isnull().values))\n",
    "  if show_missing == True:\n",
    "    print(df[df.loc[:, col_name].isnull()])\n",
    "print(missing_val_count(pv_df, 'state'))\n",
    "\n",
    "\n",
    "def drop_n_reset(df):\n",
    "  '''Drop all missing rows, duplicates, and reset the index.'''\n",
    "  df = df.dropna(axis=0, how='all').drop_duplicates()\n",
    "  df = df.reset_index(drop=True)\n",
    "drop_n_reset(pv_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVERT DATA TYPES AND REMOVE STRINGS/SYMBOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "['TX' 'CA' 'IN' 'OK' 'OH' 'IL' 'VA' 'WI' 'CO' 'MD' 'FL' 'NY' 'MA' 'PA' 'AZ'\n",
      " 'UT' 'KY' 'DE' 'WA' 'IA' 'MS' 'HI' 'KS' 'GA' 'ME' 'NH' 'CT' 'VT' 'NM' 'AL'\n",
      " 'MO' 'NJ' 'AK' 'MN' 'MI' 'MT' 'ID' 'SD' 'ND' 'RI' 'NE' 'TN' 'DC' 'OR' 'LA'\n",
      " 'AR' 'WV' 'WY' 'NC' 'NV' 'SC' 'PR' 'OH ' 'MD ' 'PA ']\n"
     ]
    }
   ],
   "source": [
    "# NUMBER OF STATES\n",
    "print(pv_df.state.nunique()) # number of unique states\n",
    "print(pv_df.state.unique()) # OH, MD and PA contain an empty string, PR and DC are not states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost <- dtype is object but contains digits\n",
      "rebate <- dtype is object but contains digits\n"
     ]
    }
   ],
   "source": [
    "# NOTE: cost and rebate columns are dtype 'object' although they are supposed to be numeric\n",
    "# test for any digits within character strings\n",
    "col = list(pv_df.columns)\n",
    "for item in col:\n",
    "  if pv_df[item].dtype == np.object:\n",
    "      if pv_df[item].str.isnumeric().any():\n",
    "        print(item, '<- dtype is object but contains digits')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Cost and rebate do not convert due to error. Strings must be replaced before dtype conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pv_df.loc[:, 'cost'] = pv_df.loc[:, 'cost'].values.astype(float)\n",
    "pv_df.loc[:, 'rebate'] = pv_df.loc[:, 'rebate'].values.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCTION: look for string 'n/a', dollar sign '$', string 'null', and comma ','\n",
    "# strip all leading and trailing whitespaces\n",
    "def remove_symbols(df):\n",
    "  '''For columns which are dtype 'object', strip all leading and trailing whitespaces\n",
    "  remove unwanted strings/symbols such as dollar sign and comma used in currency.\n",
    "  Replace the string 'n/a' and 'null' with a numeric zero'''\n",
    "  cols = list(df.columns)\n",
    "  for item in cols:\n",
    "    if df.loc[:, item].dtype == np.object:\n",
    "      df.loc[:, item] = df.loc[:, item].str.strip('$')\n",
    "      df.loc[:, item] = df.loc[:, item].replace(['n/a', 'null'], 0)\n",
    "    # target specific columns\n",
    "    elif item == 'state':\n",
    "      df.loc[:, 'state'] = df.loc[:, 'state'].str.rstrip()\n",
    "  return df\n",
    "pv_df = remove_symbols(pv_df)\n",
    "\n",
    "pv_df.loc[:, 'rebate'] = pv_df.loc[:, 'rebate'].str.replace(',', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# confirm removal of unwanted characters\n",
    "conditions = [pv_df['cost'].str.contains('n/a').any(), pv_df['rebate'].str.contains('\\$').any(),\n",
    "              pv_df['rebate'].str.contains(',').any(), pv_df['rebate'].str.contains('null').any()]\n",
    "# check for conditions being satisfied\n",
    "for item in conditions:\n",
    "  if item:\n",
    "    print(conditions)\n",
    "    print(\"Test failed. You're not done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert zeros to NaNs since cost cannot be zero\n",
    "pv_df.loc[:, 'cost']= pv_df.loc[:, 'cost'].replace(0, np.nan)\n",
    "\n",
    "# CONVERT TO FLOAT\n",
    "pv_df.loc[:, 'cost'] = pv_df.loc[:, 'cost'].values.astype(float)\n",
    "pv_df.loc[:, 'rebate'] = pv_df.loc[:, 'rebate'].values.astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOWER CASE\n",
    "Convert data types prior to Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_installed -converted to lower case\n",
      "city -converted to lower case\n",
      "state -converted to lower case\n",
      "county -converted to lower case\n",
      "incentive_prog_names -converted to lower case\n",
      "install_type -converted to lower case\n",
      "installer -converted to lower case\n",
      "utility_clean -converted to lower case\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create function to to test data type and convert to lower case\n",
    "def upper_to_lower(df):\n",
    "  ''' Test each column for data type 'object', then convert to lower case '''\n",
    "\n",
    "  col_name = list(df.columns)\n",
    "  # iterate over columns\n",
    "  for item in col_name:\n",
    "    # if data type is object, then convert column to lower case\n",
    "    if df[item].dtype == np.object:\n",
    "      df.loc[:, item] = df.loc[:, item].str.lower()\n",
    "      print(item, '-converted to lower case')\n",
    "  return df\n",
    "pv_df = upper_to_lower(pv_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ZIPCODES\n",
    "\n",
    "Zipcode column contains to many three and four digit zipcodes, some of which turned out to be invalid. This column will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'missing_val_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-155f74979b93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;31m# count missing values created in the 'state' column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmissing_val_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpv_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'state'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;31m# pv_df.info()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'missing_val_count' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# create missing values in 'state' column then drop rows\n",
    "pv_df[pv_df['zipcode']==0]=np.nan\n",
    "# pv_df['zipcode'] = np.nan_to_num(pv_df['zipcode'].values).astype(int)\n",
    "\n",
    "# count missing values created in the 'state' column\n",
    "missing_val_count(pv_df, 'state', True)\n",
    "\n",
    "# pv_df.info()\n",
    "# drop NA rows, duplicates and reset index\n",
    "pv_df = pv_df.dropna(axis=0, how='all').drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# NOTE: some zipcodes have only 3 or 4 digits with missing zeros. Consider REMOVING\n",
    "pv_df = pv_df.sort_values(by = ['zipcode'])\n",
    "pv_df.loc[1950:2000, 'zipcode']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some zipcodes have only 3 or 4 digits with missing leading zeros as a result they will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select columns to work with further\n",
    "pv_df = pv_df[['date_installed', 'city','state', 'county', 'size_kw','annual_insolation',\n",
    "               'annual_PV_prod', 'reported_annual_energy_prod',\n",
    "               'cost_per_watt','cost','rebate', 'incentive_prog_names', 'install_type',\n",
    "               'installer','utility_clean']]\n",
    "\n",
    "\n",
    "pv_df = pv_df.dropna(axis=0, how='all').drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# found character '\\r' within 'city' column and removed it\n",
    "pv_df['city'].str.contains('\\r').any()\n",
    "pv_df['city'] = pv_df['city'].str.strip('\\r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\mouz\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e41f57d16215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0murl_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAPI_KEY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'0DkoSjFm3OJ21FRtM05Smfi9bPNoFRcJHpFNgNJw'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys_cap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys_cap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mazimuth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mazimuth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtilt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtilt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtracking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[1;31m# Package the request, send the request and catch the response: r\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m   \u001b[0mprograms_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0mprograms_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mouz\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mouz\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mouz\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    506\u001b[0m         }\n\u001b[1;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mouz\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mouz\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 )\n\u001b[1;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mouz\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mouz\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mouz\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mouz\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mouz\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mouz\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mouz\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Unexpected EOF'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mouz\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1332\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_peek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# APIs\n",
    "# =============================================================================\n",
    "\n",
    "# CREATE ADDRESS\n",
    "# create city, state combo for use in the APIs\n",
    "df = pv_df[['city', 'state', 'county']]\n",
    "df = pv_df[['state', 'county']].drop_duplicates()\n",
    "len(df)\n",
    "# concat city and state; county and state\n",
    "# create an address list\n",
    "county_state_ls = list(df['county'] + ', ' + df['state'])\n",
    "len(county_state_ls)\n",
    "# create a state list\n",
    "state_ls = list(pv_df['state'].unique())\n",
    "len(state_ls)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SOLAR RADIATION\n",
    "# =============================================================================\n",
    "cities = []\n",
    "states = []\n",
    "solrad_ = []\n",
    "url = 'https://developer.nrel.gov/api/pvwatts/v5.json?api_key={API_KEY}&address={address}&system_capacity={sys_cap}&azimuth={azimuth}&tilt={tilt}&array_type={tracking}&module_type=1&losses=10'\n",
    "for address in county_state_ls:\n",
    "  url_new = url.format(API_KEY='0DkoSjFm3OJ21FRtM05Smfi9bPNoFRcJHpFNgNJw',address=address, sys_cap=sys_cap, azimuth=azimuth, tilt=tilt, tracking=tracking)\n",
    "  # Package the request, send the request and catch the response: r\n",
    "  req = requests.get(url_new)\n",
    "  programs_data = req.json()\n",
    "  try:\n",
    "    city = programs_data['station_info']['city']\n",
    "    state = programs_data['station_info']['state']\n",
    "    solrad = programs_data['outputs']['solrad_annual']\n",
    "    cities.append(city)\n",
    "    states.append(state)\n",
    "    solrad_.append(solrad)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "sol_df = pd.DataFrame({'cities': cities, 'states':states, 'solar_rad':solrad_})\n",
    "# clean df; drop duplicates, remove underscore, and reset index\n",
    "sol_df = sol_df.drop_duplicates()\n",
    "sol_df['cities'] = sol_df['cities'].str.replace('_', ' ')\n",
    "sol_df = sol_df.reset_index(drop=True)\n",
    "\n",
    "# convert to lower case\n",
    "sol_df = upper_to_lower(sol_df)\n",
    "\n",
    "# write file\n",
    "# sol_df.to_csv('solar_rad_state.csv', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# POPULATION OF CITIES\n",
    "# =============================================================================\n",
    "cities = []\n",
    "states = []\n",
    "population = []\n",
    "for i in range(999):\n",
    "  url = 'https://public.opendatasoft.com/api/records/1.0/search/?dataset=1000-largest-us-cities-by-population-with-geographic-coordinates&rows=1000&sort=-rank&facet=city&facet=state'\n",
    "  req = requests.get(url)\n",
    "  pop_data = req.json()\n",
    "  city = pop_data['records'][i]['fields']['city']\n",
    "  state = pop_data['records'][i]['fields']['state']\n",
    "  pop = pop_data['records'][i]['fields']['population']\n",
    "  cities.append(city)\n",
    "  states.append(state)\n",
    "  population.append(pop)\n",
    "\n",
    "pop_df = pd.DataFrame({'cities': cities, 'states':states, 'population':population})\n",
    "# lower case\n",
    "pop_df = upper_to_lower(pop_df)\n",
    "\n",
    "# wrtie to csv\n",
    "pop_df.to_csv('population_df.csv', index=False)\n",
    "# read csv\n",
    "pop_df = pd.read_csv('population_df.csv', sep=',', low_memory=False)\n",
    "pop_df['states'].unique()\n",
    "pop_df['cities'].nunique()\n",
    "pop_df[pop_df['states']=='district of columbia']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INCENTIVES\n",
    "# =============================================================================\n",
    "\n",
    "incentive_missing = pv_pop[pv_pop['incentive_prog_names'].isnull()]\n",
    "incentives = incentive_missing[['city', 'state', 'incentive_prog_names']].drop_duplicates()\n",
    "address_list = list(incentives['city'] + ', ' + incentives['state'])\n",
    "\n",
    "# extract the name of program and rebate amount\n",
    "state = []\n",
    "incentive = []\n",
    "for item in address_list:\n",
    "  url = 'https://developer.nrel.gov/api/energy_incentives/v2/dsire.json?api_key={API_KEY}&address={address}&category=solar_technologies&technology=solar_photovoltaics'\n",
    "  url_new = url.format(API_KEY='0DkoSjFm3OJ21FRtM05Smfi9bPNoFRcJHpFNgNJw',address=item)\n",
    "  req = requests.get(url_new)\n",
    "  programs_data = req.json()\n",
    "\n",
    "  try:\n",
    "    # iterate over each program\n",
    "    num_prog = len(programs_data['result'])\n",
    "    for i in range(num_prog):\n",
    "      state_name = (programs_data['result'][i]['regions'][0]['name']).lower()\n",
    "      incentive_name = programs_data['result'][i]['program_name']\n",
    "      regions = programs_data['result'][i]['regions'][0]['type']\n",
    "\n",
    "      # extract info: state, and incentive program for state\n",
    "      # if program is for the state (not federal), append info to list\n",
    "      if regions == 'state':\n",
    "        state.append(state_name)\n",
    "        incentive.append(incentive_name)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "incentive_df = pd.DataFrame({'state': state, 'incentive_program': incentive})\n",
    "incentive_df = incentive_df.drop_duplicates().reset_index(drop=True)\n",
    "# lower case\n",
    "incentive_df['incentive_program'] = incentive_df['incentive_program'].str.lower()\n",
    "# write file\n",
    "incentive_df.to_csv('incentives_state.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge dataframes obtained from APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_csv(file_name):\n",
    "  df = pd.read_csv(file_name, sep=',', low_memory=False)\n",
    "  return df\n",
    "\n",
    "# open files\n",
    "sol_df = load_csv('solar_rad_state.csv')\n",
    "incent_df = load_csv('incentives_state.csv')\n",
    "states_abbv = load_csv('states_abbreviation.csv')\n",
    "pop_df = load_csv('population_df.csv')\n",
    "\n",
    "# merge pop_df and pv_df, MERGE on STATES\n",
    "pop_df.head()\n",
    "states_abbv.head()\n",
    "pv_df2 = pd.merge(pv_df, states_abbv, left_on='state', right_on='abbreviation', how='left').dropna(axis=0, how='all').drop_duplicates()\n",
    "pv_df2 = pv_df2.reset_index(drop=True)\n",
    "pv_df2.head()\n",
    "pv_df2 = pv_df2[['date_installed', 'city','state', 'full', 'county', 'size_kw','annual_insolation',\n",
    "               'annual_PV_prod', 'reported_annual_energy_prod','cost_per_watt','cost','sales_tax_cost','rebate',\n",
    "               'incentive_prog_names', 'install_type', 'installer','utility_clean']]\n",
    "pv_df2.info()\n",
    "pv_df.info()\n",
    "\n",
    "# merge population\n",
    "pv_df3 = pd.merge(pv_df2, pop_df, left_on=['city','full'], right_on=['cities','states'], how='left')\n",
    "pv_df3 = pv_df3.dropna(axis=0, how='all').drop_duplicates().reset_index(drop=True)\n",
    "pv_df3.info()\n",
    "pv_df3.head()\n",
    "pv_df3 = pv_df3[['date_installed', 'city','state', 'full', 'county', 'population', 'size_kw','annual_insolation',\n",
    "               'annual_PV_prod', 'reported_annual_energy_prod','cost_per_watt','cost', 'sales_tax_cost', 'rebate',\n",
    "               'incentive_prog_names', 'install_type', 'installer','utility_clean']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pv_df = pv_df3\n",
    "# rename columns\n",
    "pv_df3.columns = ['date_installed', 'city', 'state_short', 'state', 'county', 'population',\n",
    "                 'size_kw', 'annual_insolation', 'annual_pv_prod',\n",
    "                 'reported_annual_energy_prod', 'cost_per_watt', 'cost','sales_tax_cost', 'rebate',\n",
    "                 'incentive_prog_names', 'install_type', 'installer', 'utility']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pv_df['county'].str.contains('st. louis').any()\n",
    "pv_df['county'].str.contains('st louis').any()\n",
    "# found both: 'st. louis' and 'st louis' in county column\n",
    "pv_df[pv_df['county']=='st. louis']\n",
    "pv_df[pv_df['state']=='mo']\n",
    "\n",
    "# remove the period from 'st.' to maintain consistency\n",
    "pv_df['city'] = pv_df['city'].str.replace('.', '')\n",
    "pv_df['county'] = pv_df['county'].str.replace('.', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SIZE KW\n",
    "# =============================================================================\n",
    "# show summary statistics\n",
    "pv_df.size_kw.describe()\n",
    "missing_val_count(pv_df, 'size_kw', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INCENTIVE_PROG_NAMES\n",
    "# =============================================================================\n",
    "# explore the missing values\n",
    "missing_val_count(pv_df, 'incentive_prog_names', True)\n",
    "pv_df.incentive_prog_names.describe()\n",
    "pv_df.incentive_prog_names.unique()\n",
    "\n",
    "# unique values\n",
    "pv_df['incentive_prog_names'].nunique()\n",
    "\n",
    "# frequency count of programs\n",
    "pv_df.groupby(['incentive_prog_names'])['state'].value_counts().sort_values()\n",
    "\n",
    "\n",
    "# REBATE for each state\n",
    "# median rebate offered by each program\n",
    "pv_df.groupby(['incentive_prog_names'])['rebate'].median().sort_values()\n",
    "\n",
    "pv_df.groupby(['state'])['rebate'].median().sort_values()\n",
    "pv_df.groupby(['state'])['cost'].median().sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MISSING VALUES: cost\n",
    "# =============================================================================\n",
    "missing_val_count(pv_df, 'cost', True) # 266,670\n",
    "pv_df['cost'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# # SUMMARY STATS: cost_per_watt\n",
    "# =============================================================================\n",
    "pv_df['cost_per_watt'].describe()\n",
    "missing_val_count(pv_df, 'cost_per_watt', True) # 266,914\n",
    "missing_val_count(pv_df, 'size_kw', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# explore the columns\n",
    "pv_df[['cost_per_watt', 'cost', 'size_kw', 'annual_pv_prod']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MISSING VALUES: cost_per_watt\n",
    "# =============================================================================\n",
    "\n",
    "# FILL COST_PER_WATT\n",
    "# cost per watt = cost / kw*1000\n",
    "# fill in missing COST_PER_WATT based on cost and size\n",
    "pv_df['cost_per_watt'] = pv_df['cost_per_watt'].fillna(pv_df['cost'] / (pv_df['size_kw']*1000))\n",
    "\n",
    "# FILL COST\n",
    "# cost = cost_per_watt * (size*1000)\n",
    "# fill in missing COST values based on SIZE and COST_PER_WATT\n",
    "fill_cost = (pv_df['cost_per_watt']*(pv_df['size_kw']*1000))\n",
    "pv_df['cost'] = pv_df['cost'].fillna(fill_cost)\n",
    "\n",
    "cost = pv_df['cost'] / (pv_df['size_kw']*1000)\n",
    "cost.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# # SUMMARY STATS: annual_PV_prod (estimated production)\n",
    "# =============================================================================\n",
    "\n",
    "# having all values for 'size_kw', fill in missing values in 'annual_pv_prod'\n",
    "pv_df['annual_pv_prod'].describe()\n",
    "missing_val_count(pv_df, 'annual_pv_prod',True) # 226010\n",
    "pv_df[['annual_pv_prod', 'size_kw', 'annual_insolation']]\n",
    "\n",
    "\n",
    "# annual energy production = annual_pv_produced/system_size\n",
    "common_denom = pv_df['annual_pv_prod']/pv_df['size_kw']\n",
    "common_denom.describe()\n",
    "np.count_nonzero(common_denom.isnull().values) # 239608\n",
    "\n",
    "# fill missing values within common_denom using its median\n",
    "common_denom = common_denom.fillna(common_denom.median())\n",
    "\n",
    "# infered annual production = common_denom*size\n",
    "annual_pv_infer = common_denom*pv_df['size_kw']\n",
    "annual_pv_infer.describe()\n",
    "\n",
    "# check the error between actual and calculated energy production\n",
    "error = abs(annual_pv_infer - pv_df['annual_pv_prod'])/pv_df['annual_pv_prod']\n",
    "error.describe()\n",
    "# fill missing values\n",
    "pv_df['annual_pv_prod'] = pv_df['annual_pv_prod'].fillna(annual_pv_infer)\n",
    "pv_df['annual_pv_prod'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SUMMARY STATS: reported_annual_energy_prod\n",
    "# =============================================================================\n",
    "# count and explore missing values\n",
    "# 833,466 missing values\n",
    "missing_val_count(pv_df, 'reported_annual_energy_prod', True)\n",
    "# this may be too many missing values to fill as it may lead to a lrager error\n",
    "\n",
    "pv_df['reported_annual_energy_prod'].describe()\n",
    "\n",
    "pv_df[['reported_annual_energy_prod', 'annual_pv_prod']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MISSING VALUES: reported_annual_energy_prod\n",
    "# =============================================================================\n",
    "\n",
    "# calculate error between estimated and reported annual PV production\n",
    "error = abs(pv_df['reported_annual_energy_prod'] - pv_df['annual_pv_prod'])/pv_df['annual_pv_prod']\n",
    "error.describe()\n",
    "error.mean() # 0.1083\n",
    "error.median() # 0.0691\n",
    "\n",
    "# fill REPORTED_ANNUAL_ENERGY_PROD missing values based on error from estimated ANNUAL_PV_PROD\n",
    "infer_reported = pv_df['annual_pv_prod']*error.mean()\n",
    "pv_df['reported_annual_energy_prod'] = pv_df['reported_annual_energy_prod'].fillna(infer_reported)\n",
    "pv_df['reported_annual_energy_prod'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SUMMARY STATS: annual_insolation\n",
    "# use API to fill missing values\n",
    "# =============================================================================\n",
    "missing_val_count(pv_df, 'annual_insolation')\n",
    "pv_df['annual_insolation'].describe()\n",
    "\n",
    "# explore: insolation rate for each state\n",
    "# insolation too high for some states: DO NOT USE\n",
    "state_insol = pv_df.groupby('state')['annual_insolation'].mean()\n",
    "state_insol.sort_values()\n",
    "state_insol.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# install type, consolidate\n",
    "# =============================================================================\n",
    "pv_df['install_type'].unique()\n",
    "\n",
    "pv_df[pv_df['install_type']==\"customer\"]\n",
    "pv_df[pv_df['install_type']==\"unknown\"]\n",
    "pv_df['install_type'].str.contains(\"gov't/np\").value_counts()\n",
    "\n",
    "# consolidate all commercial type\n",
    "comr_ls = ['commerical','commercial - agriculture', 'small business', 'commercial - small business',\n",
    "               'commercial - builders', 'commercial - other', 'commercial']\n",
    "pv_df['install_type'] = pv_df['install_type'].replace(comr_ls, 'commercial')\n",
    "\n",
    "# government\n",
    "pv_df['install_type'] = pv_df['install_type'].replace(\"gov't/np\", 'government')\n",
    "\n",
    "# educational\n",
    "pv_df['install_type'] = pv_df['install_type'].replace(\"education\", 'educational')\n",
    "\n",
    "# agricultural\n",
    "pv_df['install_type'] = pv_df['install_type'].replace(\"agriculture\", 'agricultural')\n",
    "\n",
    "# residential\n",
    "pv_df['install_type'] = pv_df['install_type'].replace('residential/sf', 'residential')\n",
    "\n",
    "# residential\n",
    "pv_df['install_type'] = pv_df['install_type'].replace('not stated', 'unknown')\n",
    "\n",
    "# view the missing values\n",
    "pv_df[pv_df['install_type'].isnull()]\n",
    "\n",
    "# fill missing values with 'unknown'\n",
    "pv_df['install_type'] = pv_df['install_type'].fillna('unknown')\n",
    "\n",
    "pv_df['install_type'] = pv_df['install_type'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fills in missing values for annual solar radiation using the dataframe created through an API for annual \n",
    "# solar radiation as a refrence\n",
    "def reference_fill(df_target, col1, col2, df_ref, col3, col4):\n",
    "  '''Fill in missing values in df_target based on known values from df_ref column'''\n",
    "  # iterate over the known values in reference column\n",
    "  ls = list(df_ref[col3])\n",
    "  for item in df_ref[col3]:\n",
    "    # 1. REFERENCE: find position of unique item in column\n",
    "    # 2. REFERENCE: extract row and contents\n",
    "    # 3. TARGET: find position to fill\n",
    "    # 4. TARGET: fill in value in found position with reference value\n",
    "    \n",
    "    # REFERENCE\n",
    "    try:\n",
    "      row = df_ref[(df_ref[col3]==item)].index[0]\n",
    "      name = df_ref.loc[row, col4] # replacement value\n",
    "      # TARGET\n",
    "      rows = df_target[(df_target.loc[:, col1]==item)].index\n",
    "      df_target.loc[rows, col2] = df_target.loc[rows, col2].fillna(name)\n",
    "    except:\n",
    "      pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INSOLATION\n",
    "sol_df.head()\n",
    "pv_df.head()\n",
    "\n",
    "reference_fill(pv_df, 'state_short', 'annual_insolation', sol_df, 'states', 'solar_rad')\n",
    "missing_val_count(pv_df, 'annual_insolation', True) # 225,394\n",
    "pv_df['annual_insolation'].describe()\n",
    "\n",
    "# missing city for capital, DC\n",
    "# fill with 'washington'\n",
    "missing_val_count(pv_df, 'annual_insolation', True) # missing only in DC\n",
    "pv_df[pv_df['state_short']=='dc']\n",
    "rows = pv_df[(pv_df.loc[:, 'state_short']=='dc')].index\n",
    "pv_df.loc[rows, 'city'] = pv_df.loc[rows, 'city'].fillna('washington')\n",
    "\n",
    "\n",
    "sol_df[sol_df['states']=='dc']\n",
    "sol_df['states'].nunique()\n",
    "sol_df[sol_df['states']=='va']\n",
    "\n",
    "# fill 'insolation' for DC with VA's\n",
    "rows = pv_df[(pv_df.loc[:, 'state_short']=='dc')].index\n",
    "pv_df.loc[rows, 'annual_insolation'] = pv_df.loc[rows, 'annual_insolation'].fillna(4.6741948)\n",
    "missing_val_count(pv_df, 'annual_insolation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pv_df['population'].describe()\n",
    "# median population\n",
    "pv_df['population'].median()\n",
    "\n",
    "# filter DF, filter by population\n",
    "pv_pop = pv_df[pv_df['population']>3.688800e+04]\n",
    "pv_pop = pv_pop.reset_index(drop=True)\n",
    "pv_pop.info()\n",
    "\n",
    "# 'installer' contains mistakes\n",
    "pv_pop['installer'].unique()\n",
    "pv_pop['installer'] = pv_pop['installer'].fillna('unknown')\n",
    "\n",
    "pv_pop['utility'].unique()\n",
    "pv_pop['utility'] = pv_pop['utility'].fillna('unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count missing values\n",
    "missing_val_count(pv_pop, 'incentive_prog_names') # 703\n",
    "missing_val_count(pv_pop, 'annual_insolation') # 6943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill in incentives' missing values\n",
    "# use incent_df as a reference to fill in missing values of incentives for state\n",
    "reference_fill(pv_pop, 'state', 'incentive_prog_names', incent_df, 'state', 'incentive_program')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INSOLATION\n",
    "sol_df.head()\n",
    "pv_df.head()\n",
    "\n",
    "reference_fill(pv_pop, 'state_short', 'annual_insolation', sol_df, 'states', 'solar_rad')\n",
    "missing_val_count(pv_pop, 'annual_insolation', True)\n",
    "pv_df['annual_insolation'].describe()\n",
    "\n",
    "# missing city for washington, DC\n",
    "# fill with 'washington'\n",
    "missing_val_count(pv_df, 'annual_insolation', True) # missing only in DC\n",
    "pv_df[pv_df['state_short']=='dc']\n",
    "rows = pv_df[(pv_df.loc[:, 'state_short']=='dc')].index\n",
    "pv_df.loc[rows, 'city'] = pv_df.loc[rows, 'city'].fillna('washington')\n",
    "\n",
    "# use neighbor's value for annual insolation\n",
    "sol_df[sol_df['states']=='dc']\n",
    "sol_df['states'].nunique()\n",
    "sol_df[sol_df['states']=='va']\n",
    "\n",
    "# fill 'insolation' for DC with VA's\n",
    "rows = pv_df[(pv_df.loc[:, 'state_short']=='dc')].index\n",
    "pv_df.loc[rows, 'annual_insolation'] = pv_df.loc[rows, 'annual_insolation'].fillna(4.6741948)\n",
    "# check again for missing values\n",
    "missing_val_count(pv_df, 'annual_insolation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write file\n",
    "# =============================================================================\n",
    "pv_pop.to_csv('pv_pop_clean.csv', encoding='utf-8', na_rep='NA', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
